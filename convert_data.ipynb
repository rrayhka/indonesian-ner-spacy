{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to train_data_json/data_train_full.json\n",
      "Data saved to test_data_json/data_test_full.json\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def extract_entities(text, regex):\n",
    "    pattern = re.compile(regex)\n",
    "    matches = pattern.finditer(text)\n",
    "    entities = []\n",
    "    clean_text = \"\"\n",
    "    last_end = 0\n",
    "    for match in matches:\n",
    "        entity_text = match.group(2)\n",
    "        entity_type = match.group(1).upper()\n",
    "        clean_text += text[last_end:match.start()]\n",
    "        start = len(clean_text)\n",
    "        clean_text += entity_text\n",
    "        end = len(clean_text)\n",
    "        entities.append((start, end, entity_type))\n",
    "        last_end = match.end()\n",
    "    clean_text += text[last_end:]\n",
    "    return clean_text, entities\n",
    "\n",
    "def convert_to_custom_format(lines, regex):\n",
    "    converted_data = []\n",
    "    for line in lines:\n",
    "        clean_text, entities = extract_entities(line.strip(), regex)\n",
    "        if clean_text:\n",
    "            converted_data.append({\n",
    "                \"text\": clean_text,\n",
    "                \"entities\": entities\n",
    "            })\n",
    "    return converted_data\n",
    "\n",
    "def process_file(file_path, regex):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "    converted_data = convert_to_custom_format(lines, regex)\n",
    "    return converted_data\n",
    "\n",
    "def save_json(data, output_file):\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "\n",
    "def process_and_save(train_file1, regex1, train_file2, regex2, output_file):\n",
    "    train_data1 = process_file(train_file1, regex1)\n",
    "    train_data2 = process_file(train_file2, regex2)\n",
    "    full_data = train_data1 + train_data2\n",
    "    save_json(full_data, output_file)\n",
    "    return full_data\n",
    "\n",
    "data_train1 = 'dataset/data_train.txt'\n",
    "data_train2 = 'dataset/training_data_enamex.txt'\n",
    "data_test1 = 'dataset/data_test.txt'\n",
    "data_test2 = 'dataset/testing_data_enamex.txt'\n",
    "regex1 = r'<(\\w+)>([^<]+)</\\1>'\n",
    "regex2 = r'<ENAMEX TYPE=\"(\\w+)\">(.*?)</ENAMEX>'\n",
    "train_data = process_and_save(data_train1, regex1, data_train2, regex2, 'train_data_json/data_train_full.json')\n",
    "test_data = process_and_save(data_test1, regex1, data_test2, regex2, 'test_data_json/data_test_full.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
